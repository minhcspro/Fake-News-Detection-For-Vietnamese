{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SnksKjwTSD0C"
      },
      "source": [
        "0: fake\n",
        "1: real\n",
        "|561.605"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "_e5MhqFhCbCX"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from transformers import PhobertTokenizer, TFRobertaModel\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, Dense, Bidirectional\n",
        "from tensorflow.keras.optimizers import Adam"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 82,
      "metadata": {},
      "outputs": [
        {
          "ename": "RuntimeError",
          "evalue": "Visible devices cannot be modified after being initialized",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[82], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m tf\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mset_visible_devices([], \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mGPU\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
            "File \u001b[0;32m~/miniconda3/lib/python3.11/site-packages/tensorflow/python/framework/config.py:566\u001b[0m, in \u001b[0;36mset_visible_devices\u001b[0;34m(devices, device_type)\u001b[0m\n\u001b[1;32m    533\u001b[0m \u001b[38;5;129m@tf_export\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mconfig.set_visible_devices\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m    534\u001b[0m            \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mconfig.experimental.set_visible_devices\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    535\u001b[0m \u001b[38;5;129m@deprecation\u001b[39m\u001b[38;5;241m.\u001b[39mdeprecated_endpoints(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mconfig.experimental.set_visible_devices\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    536\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mset_visible_devices\u001b[39m(devices, device_type\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m    537\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Set the list of visible devices.\u001b[39;00m\n\u001b[1;32m    538\u001b[0m \n\u001b[1;32m    539\u001b[0m \u001b[38;5;124;03m  Specifies which `PhysicalDevice` objects are visible to the runtime.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    564\u001b[0m \u001b[38;5;124;03m    RuntimeError: Runtime is already initialized.\u001b[39;00m\n\u001b[1;32m    565\u001b[0m \u001b[38;5;124;03m  \"\"\"\u001b[39;00m\n\u001b[0;32m--> 566\u001b[0m   context\u001b[38;5;241m.\u001b[39mcontext()\u001b[38;5;241m.\u001b[39mset_visible_devices(devices, device_type)\n",
            "File \u001b[0;32m~/miniconda3/lib/python3.11/site-packages/tensorflow/python/eager/context.py:1737\u001b[0m, in \u001b[0;36mContext.set_visible_devices\u001b[0;34m(self, devices, device_type)\u001b[0m\n\u001b[1;32m   1734\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[1;32m   1736\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_context_handle \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1737\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m   1738\u001b[0m       \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mVisible devices cannot be modified after being initialized\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   1740\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_visible_device_list \u001b[38;5;241m=\u001b[39m visible_device_list\n",
            "\u001b[0;31mRuntimeError\u001b[0m: Visible devices cannot be modified after being initialized"
          ]
        }
      ],
      "source": [
        "tf.config.set_visible_devices([], 'GPU')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some layers from the model checkpoint at vinai/phobert-base were not used when initializing TFRobertaModel: ['lm_head']\n",
            "- This IS expected if you are initializing TFRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing TFRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "All the layers of TFRobertaModel were initialized from the model checkpoint at vinai/phobert-base.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFRobertaModel for predictions without further training.\n"
          ]
        }
      ],
      "source": [
        "# T·∫£i tokenizer v√† m√¥ h√¨nh PhoBERT\n",
        "tokenizer = PhobertTokenizer.from_pretrained(\"vinai/phobert-base\")\n",
        "phobert_model = TFRobertaModel.from_pretrained(\"vinai/phobert-base\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Ma tr·∫≠n ƒë·ªçc t·ª´ file:\n",
            "[[[-0.6359838   1.1019332  -0.7713704  ... -0.1958782  -0.57587266\n",
            "    0.0297346 ]\n",
            "  [-0.06781114  0.7031037  -0.518356   ...  0.41271758  0.03433367\n",
            "   -0.55555195]\n",
            "  [-0.13347109  0.4953625  -0.7996192  ... -0.26969117 -0.10532248\n",
            "   -0.23023811]\n",
            "  ...\n",
            "  [ 0.10418507  0.3340481  -0.6007942  ... -0.3739854  -0.02259465\n",
            "    0.01876782]\n",
            "  [-0.4236371   0.50411725 -0.25576037 ... -0.43336388 -0.36910945\n",
            "    0.20797461]\n",
            "  [-0.7399383   1.0313084  -0.6763179  ... -0.01023581 -0.67881626\n",
            "    0.11209171]]\n",
            "\n",
            " [[-0.33545628  0.62904996 -0.60383403 ...  0.48500472 -0.4199828\n",
            "   -0.30491263]\n",
            "  [-0.1880203   0.04489954 -0.04217417 ...  0.28976932 -0.44473907\n",
            "   -0.25600773]\n",
            "  [-0.40234983  0.47170758  0.20504543 ...  0.34907067 -0.24179958\n",
            "    0.1116198 ]\n",
            "  ...\n",
            "  [ 0.          0.          0.         ...  0.          0.\n",
            "    0.        ]\n",
            "  [ 0.          0.          0.         ...  0.          0.\n",
            "    0.        ]\n",
            "  [ 0.          0.          0.         ...  0.          0.\n",
            "    0.        ]]\n",
            "\n",
            " [[-0.22496961  0.94353247 -0.55187976 ... -0.06172074  0.09782484\n",
            "    0.43700108]\n",
            "  [-0.33083123  0.48317325 -0.28479707 ... -0.07214262  0.0241519\n",
            "    0.7462003 ]\n",
            "  [-0.31812376  0.3378767  -0.08700804 ... -0.30511722  0.24474144\n",
            "    0.12589777]\n",
            "  ...\n",
            "  [ 0.          0.          0.         ...  0.          0.\n",
            "    0.        ]\n",
            "  [ 0.          0.          0.         ...  0.          0.\n",
            "    0.        ]\n",
            "  [ 0.          0.          0.         ...  0.          0.\n",
            "    0.        ]]\n",
            "\n",
            " ...\n",
            "\n",
            " [[-0.19321941  0.46513468 -0.16752052 ... -0.04449268 -0.14088947\n",
            "    0.07605913]\n",
            "  [-0.20298739 -0.1139716  -0.3342346  ...  0.40666994 -0.20780206\n",
            "   -0.20326701]\n",
            "  [-0.04437905 -0.07952151 -0.07749247 ... -0.04181617 -0.16852078\n",
            "   -0.8309408 ]\n",
            "  ...\n",
            "  [ 0.          0.          0.         ...  0.          0.\n",
            "    0.        ]\n",
            "  [ 0.          0.          0.         ...  0.          0.\n",
            "    0.        ]\n",
            "  [ 0.          0.          0.         ...  0.          0.\n",
            "    0.        ]]\n",
            "\n",
            " [[-0.6584144   0.9040046  -0.4281307  ... -0.08889844 -0.12823778\n",
            "    0.15355556]\n",
            "  [-0.22127631  0.3229792  -0.23698238 ...  0.09354997 -0.40717408\n",
            "   -0.4237916 ]\n",
            "  [-0.4242766   0.16607848  0.15625766 ...  0.38448614 -0.10079537\n",
            "    0.8059815 ]\n",
            "  ...\n",
            "  [ 0.          0.          0.         ...  0.          0.\n",
            "    0.        ]\n",
            "  [ 0.          0.          0.         ...  0.          0.\n",
            "    0.        ]\n",
            "  [ 0.          0.          0.         ...  0.          0.\n",
            "    0.        ]]\n",
            "\n",
            " [[ 0.27698418  0.2869505  -0.35811728 ...  0.1615237  -0.26982474\n",
            "   -0.76052123]\n",
            "  [ 0.02624241  0.38587087 -0.02134125 ...  0.03028083 -0.59329647\n",
            "   -0.16214564]\n",
            "  [ 0.2517982  -0.21126303 -0.31998137 ...  0.24038331 -0.01561478\n",
            "   -0.03540567]\n",
            "  ...\n",
            "  [ 0.          0.          0.         ...  0.          0.\n",
            "    0.        ]\n",
            "  [ 0.          0.          0.         ...  0.          0.\n",
            "    0.        ]\n",
            "  [ 0.          0.          0.         ...  0.          0.\n",
            "    0.        ]]]\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "\n",
        "# ƒê∆∞·ªùng d·∫´n ƒë·∫øn file .npy\n",
        "duong_dan_file = '/Users/quocminh/Desktop/ƒêoÃÇÃÄ AÃÅn/chinh thuc/data/data vlsp/data_goc/process/embeddings_array_train.npy'\n",
        "\n",
        "# S·ª≠ d·ª•ng np.load() ƒë·ªÉ ƒë·ªçc ma tr·∫≠n t·ª´ file\n",
        "# ma_tran_du_lieu = np.load(duong_dan_file)\n",
        "phobert_embeddings = np.load(duong_dan_file)\n",
        "# Hi·ªÉn th·ªã ma tr·∫≠n\n",
        "print(\"Ma tr·∫≠n ƒë·ªçc t·ª´ file:\")\n",
        "print(phobert_embeddings)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(6359, 106, 768)"
            ]
          },
          "execution_count": 32,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "phobert_embeddings.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ƒê·ªçc d·ªØ li·ªáu\n",
        "df = pd.read_csv(\"/Users/quocminh/Desktop/ƒêoÃÇÃÄ AÃÅn/chinh thuc/data/data vlsp/data_goc/process/train_new.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>user_name</th>\n",
              "      <th>post_message</th>\n",
              "      <th>timestamp_post</th>\n",
              "      <th>num_like_post</th>\n",
              "      <th>num_comment_post</th>\n",
              "      <th>num_share_post</th>\n",
              "      <th>label</th>\n",
              "      <th>token</th>\n",
              "      <th>token_post_message</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>f3317e52aa79b261db534a38e7f7c360</td>\n",
              "      <td>ƒê·∫æN 18H CHI·ªÄU 10/4 : TH√äM 2 CA M·∫ÆC COVID-19 ‚û°Ô∏è...</td>\n",
              "      <td>1586491781</td>\n",
              "      <td>5505</td>\n",
              "      <td>34</td>\n",
              "      <td>374.0</td>\n",
              "      <td>0</td>\n",
              "      <td>18h chi·ªÅu 104 2 ca m·∫Øc covid19 bn 256 nam 52 q...</td>\n",
              "      <td>18h chi·ªÅu 104 2 ca m·∫Øc covid19 bn 256 nam 52 q...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>cb6ad3159dd0f8cc5fa2833b22ed3c90</td>\n",
              "      <td>Th·∫ø gi·ªõi tu·∫ßn qua: N·ª£ c√¥ng M·ªπ tƒÉng kinh ho√†ng ...</td>\n",
              "      <td>2020-06-13 02:21:21</td>\n",
              "      <td>8.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>0</td>\n",
              "      <td>th·∫ø_gi·ªõi tu·∫ßn n·ª£ c√¥ng m·ªπ kinh_ho√†ng 26000 t·ª∑ u...</td>\n",
              "      <td>th·∫ø_gi·ªõi tu·∫ßn n·ª£ c√¥ng m·ªπ kinh_ho√†ng 26000 t·ª∑ u...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>0f93c7b7aedee5cd1c69cfa61787d586</td>\n",
              "      <td>S·ª±_c·ªë ƒë·ª©t c√°p AAG kh√¥ng ·∫£nh_h∆∞·ªüng t·ªõi ch·∫•t_l∆∞·ª£...</td>\n",
              "      <td>1585954578</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0</td>\n",
              "      <td>s·ª±_c·ªë ƒë·ª©t c√°p aag ·∫£nh_h∆∞·ªüng ch·∫•t_l∆∞·ª£ng trang i...</td>\n",
              "      <td>s·ª±_c·ªë ƒë·ª©t c√°p aag ·∫£nh_h∆∞·ªüng ch·∫•t_l∆∞·ª£ng trang i...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>b008022f7508beb6360b691c8c9461e5</td>\n",
              "      <td>TRI·ªÜU CH·ª®NG NHI·ªÑM CORONA QUA T·ª™NG NG√ÄY üõëNg√†y 1...</td>\n",
              "      <td>2020-03-01 18:18:51</td>\n",
              "      <td>1000.0</td>\n",
              "      <td>155.0</td>\n",
              "      <td>3000.0</td>\n",
              "      <td>1</td>\n",
              "      <td>tri·ªáu_ch·ª©ng nhi·ªÖm corona ng√†y_ng√†y 1 3 tri·ªáu_c...</td>\n",
              "      <td>tri·ªáu_ch·ª©ng nhi·ªÖm corona ng√†y_ng√†y 1 3 tri·ªáu_c...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>65c95e0460af8d14665f73aee98aec88</td>\n",
              "      <td>T·ªîN TH∆Ø∆†NG PH·ªîI C·ª¶A B·ªÜNH NH√ÇN ƒê√É CHI·∫æM 90%\\n\\n...</td>\n",
              "      <td>2020-05-13 02:45:40</td>\n",
              "      <td>5344.0</td>\n",
              "      <td>50.0</td>\n",
              "      <td>88.0</td>\n",
              "      <td>0</td>\n",
              "      <td>t·ªïn_th∆∞∆°ng ph·ªïi b·ªánh_nh√¢n chi·∫øm 90 h·ªôi_ch·∫©n li...</td>\n",
              "      <td>t·ªïn_th∆∞∆°ng ph·ªïi b·ªánh_nh√¢n chi·∫øm 90 h·ªôi_ch·∫©n li...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Unnamed: 0                         user_name  \\\n",
              "0           0  f3317e52aa79b261db534a38e7f7c360   \n",
              "1           1  cb6ad3159dd0f8cc5fa2833b22ed3c90   \n",
              "2           2  0f93c7b7aedee5cd1c69cfa61787d586   \n",
              "3           3  b008022f7508beb6360b691c8c9461e5   \n",
              "4           4  65c95e0460af8d14665f73aee98aec88   \n",
              "\n",
              "                                        post_message       timestamp_post  \\\n",
              "0  ƒê·∫æN 18H CHI·ªÄU 10/4 : TH√äM 2 CA M·∫ÆC COVID-19 ‚û°Ô∏è...           1586491781   \n",
              "1  Th·∫ø gi·ªõi tu·∫ßn qua: N·ª£ c√¥ng M·ªπ tƒÉng kinh ho√†ng ...  2020-06-13 02:21:21   \n",
              "2  S·ª±_c·ªë ƒë·ª©t c√°p AAG kh√¥ng ·∫£nh_h∆∞·ªüng t·ªõi ch·∫•t_l∆∞·ª£...           1585954578   \n",
              "3  TRI·ªÜU CH·ª®NG NHI·ªÑM CORONA QUA T·ª™NG NG√ÄY üõëNg√†y 1...  2020-03-01 18:18:51   \n",
              "4  T·ªîN TH∆Ø∆†NG PH·ªîI C·ª¶A B·ªÜNH NH√ÇN ƒê√É CHI·∫æM 90%\\n\\n...  2020-05-13 02:45:40   \n",
              "\n",
              "  num_like_post num_comment_post num_share_post  label  \\\n",
              "0          5505               34          374.0      0   \n",
              "1           8.0              2.0            4.0      0   \n",
              "2             2                0            2.0      0   \n",
              "3        1000.0            155.0         3000.0      1   \n",
              "4        5344.0             50.0           88.0      0   \n",
              "\n",
              "                                               token  \\\n",
              "0  18h chi·ªÅu 104 2 ca m·∫Øc covid19 bn 256 nam 52 q...   \n",
              "1  th·∫ø_gi·ªõi tu·∫ßn n·ª£ c√¥ng m·ªπ kinh_ho√†ng 26000 t·ª∑ u...   \n",
              "2  s·ª±_c·ªë ƒë·ª©t c√°p aag ·∫£nh_h∆∞·ªüng ch·∫•t_l∆∞·ª£ng trang i...   \n",
              "3  tri·ªáu_ch·ª©ng nhi·ªÖm corona ng√†y_ng√†y 1 3 tri·ªáu_c...   \n",
              "4  t·ªïn_th∆∞∆°ng ph·ªïi b·ªánh_nh√¢n chi·∫øm 90 h·ªôi_ch·∫©n li...   \n",
              "\n",
              "                                  token_post_message  \n",
              "0  18h chi·ªÅu 104 2 ca m·∫Øc covid19 bn 256 nam 52 q...  \n",
              "1  th·∫ø_gi·ªõi tu·∫ßn n·ª£ c√¥ng m·ªπ kinh_ho√†ng 26000 t·ª∑ u...  \n",
              "2  s·ª±_c·ªë ƒë·ª©t c√°p aag ·∫£nh_h∆∞·ªüng ch·∫•t_l∆∞·ª£ng trang i...  \n",
              "3  tri·ªáu_ch·ª©ng nhi·ªÖm corona ng√†y_ng√†y 1 3 tri·ªáu_c...  \n",
              "4  t·ªïn_th∆∞∆°ng ph·ªïi b·ªánh_nh√¢n chi·∫øm 90 h·ªôi_ch·∫©n li...  "
            ]
          },
          "execution_count": 48,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 73,
      "metadata": {},
      "outputs": [],
      "source": [
        "data = phobert_embeddings\n",
        "label = df['label']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 75,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Flatten m·∫£ng 3D th√†nh m·∫£ng 2D\n",
        "data_2d = data.reshape(data.shape[0], -1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 80,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(6359, 81408)"
            ]
          },
          "execution_count": 80,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data_2d.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(6359,)"
            ]
          },
          "execution_count": 59,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(6359,)"
            ]
          },
          "execution_count": 60,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "label.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'s·ª±_c·ªë ƒë·ª©t c√°p aag ·∫£nh_h∆∞·ªüng ch·∫•t_l∆∞·ª£ng trang internet ·ª©ng_d·ª•ng h·ªçc_t·∫≠p ƒë√†o_t·∫°o s·ª≠_d·ª•ng n·ªÅn_t·∫£ng ph·∫ßn_m·ªÅm doanh_nghi·ªáp vi·ªát_nam ph√°t_tri·ªÉn server vi·ªát_nam'"
            ]
          },
          "execution_count": 53,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data[2]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "# T·∫°o vector h√≥a TF-IDF\n",
        "vectorizer = TfidfVectorizer()\n",
        "X_train_tfidf = vectorizer.fit_transform(data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(6359, 23745)"
            ]
          },
          "execution_count": 64,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X_train_tfidf.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 78,
      "metadata": {},
      "outputs": [],
      "source": [
        "from imblearn.over_sampling import SMOTE\n",
        "smote = SMOTE(random_state=42)\n",
        "X_train_resampled, y_train_resampled = smote.fit_resample(data_2d, label)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 79,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(10522, 81408)"
            ]
          },
          "execution_count": 79,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X_train_resampled.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(10522,)"
            ]
          },
          "execution_count": 71,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "y_train_resampled.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 88,
      "metadata": {},
      "outputs": [],
      "source": [
        "# X√°c ƒë·ªãnh k√≠ch th∆∞·ªõc c·ªßa m·∫£ng 3D m·ªõi\n",
        "num_samples = X_train_resampled.shape[0]\n",
        "max_seq_length = 106  # ƒê·ªô d√†i chu·ªói t·ªëi ƒëa cho m·ªói m·∫´u trong m·∫£ng 3D m·ªõi\n",
        "embedding_size = 768  # K√≠ch th∆∞·ªõc c·ªßa embedding cho m·ªói ph·∫ßn t·ª≠ trong chu·ªói\n",
        "\n",
        "# S·ª≠ d·ª•ng reshape ƒë·ªÉ chuy·ªÉn t·ª´ 2D sang 3D\n",
        "data_3d = X_train_resampled.reshape(num_samples, max_seq_length, embedding_size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 90,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(10522, 106, 768)"
            ]
          },
          "execution_count": 90,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data_3d.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[-0.15379545,  0.616008  , -0.6380138 , ..., -0.01640839,\n",
              "        -0.27363673, -0.72130424],\n",
              "       [-0.0289081 , -0.3191048 , -0.10481234, ...,  0.04813703,\n",
              "        -0.09355595,  0.46457505],\n",
              "       [ 0.31515437,  0.13389817,  0.11998722, ..., -0.05407841,\n",
              "        -0.4661887 , -0.26282856],\n",
              "       ...,\n",
              "       [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
              "         0.        ,  0.        ],\n",
              "       [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
              "         0.        ,  0.        ],\n",
              "       [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
              "         0.        ,  0.        ]], dtype=float32)"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data[16]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(8000, 256, 768)\n",
            "(8000,)\n",
            "(1000, 256, 768)\n",
            "(1000,)\n",
            "(1000, 256, 768)\n",
            "(1000,)\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "(None, None)"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_rem, y_train, y_rem = train_test_split(data, label, train_size= 0.8)\n",
        "\n",
        "# Now since we want the valid and test size to be equal (10% each of overall data).\n",
        "# we have to define valid_size=0.5 (that is 50% of remaining data)\n",
        "test_size = 0.5\n",
        "X_valid, X_test, y_valid, y_test = train_test_split(X_rem,y_rem, test_size=0.5)\n",
        "\n",
        "print(X_train.shape), print(y_train.shape)\n",
        "print(X_valid.shape), print(y_valid.shape)\n",
        "print(X_test.shape), print(y_test.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [],
      "source": [
        "tf.config.set_visible_devices([], 'GPU')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 91,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " bidirectional_2 (Bidirecti  (None, 106, 256)          918528    \n",
            " onal)                                                           \n",
            "                                                                 \n",
            " bidirectional_3 (Bidirecti  (None, 128)               164352    \n",
            " onal)                                                           \n",
            "                                                                 \n",
            " dense (Dense)               (None, 32)                4128      \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 1)                 33        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1087041 (4.15 MB)\n",
            "Trainable params: 1087041 (4.15 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Bidirectional, LSTM, Dense, Dropout\n",
        "\n",
        "# K√≠ch th∆∞·ªõc c·ªßa vector embedding PhoBERT\n",
        "embedding_shape = (106, 768)\n",
        "\n",
        "# S·ªë l·ªõp ƒë·∫ßu ra (t√πy thu·ªôc v√†o s·ªë l∆∞·ª£ng nh√£n trong d·ªØ li·ªáu c·ªßa b·∫°n)\n",
        "num_classes = 1\n",
        "\n",
        "# T·∫°o m√¥ h√¨nh Bi-LSTM\n",
        "model = Sequential()\n",
        "model.add(Bidirectional(LSTM(128, return_sequences=True), input_shape=embedding_shape))\n",
        "# model.add(Dropout(0.5))\n",
        "model.add(Bidirectional(LSTM(64)))\n",
        "# model.add(Dropout(0.5))\n",
        "model.add(Dense(32, activation='relu'))\n",
        "# model.add(Dropout(0.5))\n",
        "model.add(Dense(num_classes, activation='sigmoid'))\n",
        "\n",
        "# Compile m√¥ h√¨nh\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# In th√¥ng tin t√≥m t·∫Øt c·ªßa m√¥ h√¨nh\n",
        "model.summary()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 92,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/200\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2024-02-03 13:04:03.261214: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:117] Plugin optimizer for device_type GPU is enabled.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "264/264 [==============================] - 30s 91ms/step - loss: 0.3329 - accuracy: 0.8543 - val_loss: 0.1645 - val_accuracy: 0.9520\n",
            "Epoch 2/200\n",
            "264/264 [==============================] - 21s 81ms/step - loss: 0.1541 - accuracy: 0.9410 - val_loss: 0.0246 - val_accuracy: 0.9933\n",
            "Epoch 3/200\n",
            "264/264 [==============================] - 20s 77ms/step - loss: 0.1325 - accuracy: 0.9501 - val_loss: 0.0337 - val_accuracy: 0.9933\n",
            "Epoch 4/200\n",
            "264/264 [==============================] - 20s 77ms/step - loss: 0.0564 - accuracy: 0.9818 - val_loss: 0.0704 - val_accuracy: 0.9729\n",
            "Epoch 5/200\n",
            "264/264 [==============================] - 20s 77ms/step - loss: 0.0372 - accuracy: 0.9885 - val_loss: 0.0072 - val_accuracy: 0.9967\n",
            "Epoch 6/200\n",
            "264/264 [==============================] - 20s 77ms/step - loss: 0.0245 - accuracy: 0.9922 - val_loss: 0.0393 - val_accuracy: 0.9862\n",
            "Epoch 7/200\n",
            "264/264 [==============================] - 20s 77ms/step - loss: 0.0152 - accuracy: 0.9956 - val_loss: 0.0031 - val_accuracy: 1.0000\n",
            "Epoch 8/200\n",
            "264/264 [==============================] - 20s 77ms/step - loss: 0.0251 - accuracy: 0.9912 - val_loss: 0.0050 - val_accuracy: 0.9995\n",
            "Epoch 9/200\n",
            "264/264 [==============================] - 20s 77ms/step - loss: 0.0119 - accuracy: 0.9957 - val_loss: 2.2121e-04 - val_accuracy: 1.0000\n",
            "Epoch 10/200\n",
            "264/264 [==============================] - 20s 77ms/step - loss: 0.0114 - accuracy: 0.9964 - val_loss: 0.0032 - val_accuracy: 0.9995\n",
            "Epoch 11/200\n",
            "264/264 [==============================] - 20s 77ms/step - loss: 0.0117 - accuracy: 0.9963 - val_loss: 0.0016 - val_accuracy: 0.9990\n",
            "Epoch 12/200\n",
            "264/264 [==============================] - 20s 77ms/step - loss: 0.0078 - accuracy: 0.9979 - val_loss: 5.0412e-04 - val_accuracy: 1.0000\n",
            "Epoch 13/200\n",
            "264/264 [==============================] - 21s 78ms/step - loss: 0.0067 - accuracy: 0.9977 - val_loss: 2.6842e-04 - val_accuracy: 1.0000\n",
            "Epoch 14/200\n",
            "264/264 [==============================] - 21s 78ms/step - loss: 0.0049 - accuracy: 0.9983 - val_loss: 0.0068 - val_accuracy: 0.9981\n",
            "Epoch 15/200\n",
            "264/264 [==============================] - 20s 78ms/step - loss: 0.0143 - accuracy: 0.9948 - val_loss: 0.0139 - val_accuracy: 0.9957\n",
            "Epoch 16/200\n",
            "264/264 [==============================] - 21s 77ms/step - loss: 0.0159 - accuracy: 0.9942 - val_loss: 2.6144e-04 - val_accuracy: 1.0000\n",
            "Epoch 17/200\n",
            "264/264 [==============================] - 21s 79ms/step - loss: 0.0064 - accuracy: 0.9976 - val_loss: 0.0012 - val_accuracy: 1.0000\n",
            "Epoch 18/200\n",
            "264/264 [==============================] - 21s 78ms/step - loss: 0.0023 - accuracy: 0.9990 - val_loss: 4.5536e-04 - val_accuracy: 1.0000\n",
            "Epoch 19/200\n",
            "264/264 [==============================] - 21s 78ms/step - loss: 0.0018 - accuracy: 0.9994 - val_loss: 4.1890e-04 - val_accuracy: 1.0000\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x35b5f1010>"
            ]
          },
          "execution_count": 92,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Hu·∫•n luy·ªán m√¥ h√¨nh tr√™n d·ªØ li·ªáu c·ªßa b·∫°n (data v√† label)\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "# Thay th·∫ø data v√† label b·∫±ng d·ªØ li·ªáu v√† nh√£n th·ª±c t·∫ø c·ªßa b·∫°n\n",
        "# T·ª± d·ª´ng h·ªçc khi kh√¥ng c·∫£i thi·ªán validation loss trong 10 epoch\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
        "\n",
        "# Hu·∫•n luy·ªán m√¥ h√¨nh v·ªõi t·ª± d·ª´ng h·ªçc\n",
        "# history = model.fit(X_train, y_train, epochs=100, validation_data=(x_val, y_val), callbacks=[early_stopping])\n",
        "\n",
        "model.fit(data_3d, y_train_resampled, epochs=200, batch_size=32, validation_split=0.2, callbacks=[early_stopping])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 127,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_test = pd.read_csv('/Users/quocminh/Desktop/ƒêoÃÇÃÄ AÃÅn/chinh thuc/data/data vlsp/data_goc/process/test_new.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 128,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Ma tr·∫≠n ƒë·ªçc t·ª´ file:\n",
            "[[[-0.6359838   1.1019332  -0.7713704  ... -0.1958782  -0.57587266\n",
            "    0.0297346 ]\n",
            "  [-0.06781114  0.7031037  -0.518356   ...  0.41271758  0.03433367\n",
            "   -0.55555195]\n",
            "  [-0.13347109  0.4953625  -0.7996192  ... -0.26969117 -0.10532248\n",
            "   -0.23023811]\n",
            "  ...\n",
            "  [ 0.10418507  0.3340481  -0.6007942  ... -0.3739854  -0.02259465\n",
            "    0.01876782]\n",
            "  [-0.4236371   0.50411725 -0.25576037 ... -0.43336388 -0.36910945\n",
            "    0.20797461]\n",
            "  [-0.7399383   1.0313084  -0.6763179  ... -0.01023581 -0.67881626\n",
            "    0.11209171]]\n",
            "\n",
            " [[-0.33545628  0.62904996 -0.60383403 ...  0.48500472 -0.4199828\n",
            "   -0.30491263]\n",
            "  [-0.1880203   0.04489954 -0.04217417 ...  0.28976932 -0.44473907\n",
            "   -0.25600773]\n",
            "  [-0.40234983  0.47170758  0.20504543 ...  0.34907067 -0.24179958\n",
            "    0.1116198 ]\n",
            "  ...\n",
            "  [ 0.          0.          0.         ...  0.          0.\n",
            "    0.        ]\n",
            "  [ 0.          0.          0.         ...  0.          0.\n",
            "    0.        ]\n",
            "  [ 0.          0.          0.         ...  0.          0.\n",
            "    0.        ]]\n",
            "\n",
            " [[-0.22496961  0.94353247 -0.55187976 ... -0.06172074  0.09782484\n",
            "    0.43700108]\n",
            "  [-0.33083123  0.48317325 -0.28479707 ... -0.07214262  0.0241519\n",
            "    0.7462003 ]\n",
            "  [-0.31812376  0.3378767  -0.08700804 ... -0.30511722  0.24474144\n",
            "    0.12589777]\n",
            "  ...\n",
            "  [ 0.          0.          0.         ...  0.          0.\n",
            "    0.        ]\n",
            "  [ 0.          0.          0.         ...  0.          0.\n",
            "    0.        ]\n",
            "  [ 0.          0.          0.         ...  0.          0.\n",
            "    0.        ]]\n",
            "\n",
            " ...\n",
            "\n",
            " [[-0.19321941  0.46513468 -0.16752052 ... -0.04449268 -0.14088947\n",
            "    0.07605913]\n",
            "  [-0.20298739 -0.1139716  -0.3342346  ...  0.40666994 -0.20780206\n",
            "   -0.20326701]\n",
            "  [-0.04437905 -0.07952151 -0.07749247 ... -0.04181617 -0.16852078\n",
            "   -0.8309408 ]\n",
            "  ...\n",
            "  [ 0.          0.          0.         ...  0.          0.\n",
            "    0.        ]\n",
            "  [ 0.          0.          0.         ...  0.          0.\n",
            "    0.        ]\n",
            "  [ 0.          0.          0.         ...  0.          0.\n",
            "    0.        ]]\n",
            "\n",
            " [[-0.6584144   0.9040046  -0.4281307  ... -0.08889844 -0.12823778\n",
            "    0.15355556]\n",
            "  [-0.22127631  0.3229792  -0.23698238 ...  0.09354997 -0.40717408\n",
            "   -0.4237916 ]\n",
            "  [-0.4242766   0.16607848  0.15625766 ...  0.38448614 -0.10079537\n",
            "    0.8059815 ]\n",
            "  ...\n",
            "  [ 0.          0.          0.         ...  0.          0.\n",
            "    0.        ]\n",
            "  [ 0.          0.          0.         ...  0.          0.\n",
            "    0.        ]\n",
            "  [ 0.          0.          0.         ...  0.          0.\n",
            "    0.        ]]\n",
            "\n",
            " [[ 0.27698418  0.2869505  -0.35811728 ...  0.1615237  -0.26982474\n",
            "   -0.76052123]\n",
            "  [ 0.02624241  0.38587087 -0.02134125 ...  0.03028083 -0.59329647\n",
            "   -0.16214564]\n",
            "  [ 0.2517982  -0.21126303 -0.31998137 ...  0.24038331 -0.01561478\n",
            "   -0.03540567]\n",
            "  ...\n",
            "  [ 0.          0.          0.         ...  0.          0.\n",
            "    0.        ]\n",
            "  [ 0.          0.          0.         ...  0.          0.\n",
            "    0.        ]\n",
            "  [ 0.          0.          0.         ...  0.          0.\n",
            "    0.        ]]]\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "\n",
        "# ƒê∆∞·ªùng d·∫´n ƒë·∫øn file .npy\n",
        "duong_dan_file = '/Users/quocminh/Desktop/ƒêoÃÇÃÄ AÃÅn/chinh thuc/data/data vlsp/data_goc/process/embeddings_array_test.npy'\n",
        "\n",
        "# S·ª≠ d·ª•ng np.load() ƒë·ªÉ ƒë·ªçc ma tr·∫≠n t·ª´ file\n",
        "# ma_tran_du_lieu = np.load(duong_dan_file)\n",
        "phobert_embeddings_test = np.load(duong_dan_file)\n",
        "# Hi·ªÉn th·ªã ma tr·∫≠n\n",
        "print(\"Ma tr·∫≠n ƒë·ªçc t·ª´ file:\")\n",
        "print(phobert_embeddings)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 129,
      "metadata": {},
      "outputs": [],
      "source": [
        "X_test = phobert_embeddings_test\n",
        "y_test = df_test['label']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 96,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "11/11 [==============================] - 2s 77ms/step\n",
            "Accuracy: 0.8424068767908309\n",
            "Confusion Matrix:\n",
            " [[230  53]\n",
            " [  2  64]]\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.99      0.81      0.89       283\n",
            "           1       0.55      0.97      0.70        66\n",
            "\n",
            "    accuracy                           0.84       349\n",
            "   macro avg       0.77      0.89      0.80       349\n",
            "weighted avg       0.91      0.84      0.86       349\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
        "\n",
        "# Gi·∫£ s·ª≠ model l√† m√¥ h√¨nh b·∫°n ƒë√£ hu·∫•n luy·ªán v√† test_data l√† t·∫≠p d·ªØ li·ªáu ki·ªÉm th·ª≠\n",
        "test_predictions = model.predict(X_test)\n",
        "\n",
        "# Chuy·ªÉn ƒë·ªïi d·ª± ƒëo√°n th√†nh nh√£n (v√≠ d·ª•: v·ªõi m√¥ h√¨nh binary classification)\n",
        "predicted_labels = (test_predictions > 0.5).astype(int)\n",
        "\n",
        "# ƒê√°nh gi√° m√¥ h√¨nh\n",
        "accuracy = accuracy_score(y_test, predicted_labels)\n",
        "conf_matrix = confusion_matrix(y_test, predicted_labels)\n",
        "classification_rep = classification_report(y_test, predicted_labels)\n",
        "\n",
        "# In c√°c ƒë·ªô ƒëo\n",
        "print(\"Accuracy:\", accuracy)\n",
        "print(\"Confusion Matrix:\\n\", conf_matrix)\n",
        "print(\"Classification Report:\\n\", classification_rep)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 97,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "11/11 [==============================] - 0s 40ms/step - loss: 0.6360 - accuracy: 0.8424\n",
            "Loss: 0.6360059380531311, Accuracy: 0.8424068689346313\n"
          ]
        }
      ],
      "source": [
        "# ƒê√°nh gi√° m√¥ h√¨nh tr√™n t·∫≠p ki·ªÉm tra\n",
        "loss, accuracy = model.evaluate(X_test, y_test)\n",
        "print(f\"Loss: {loss}, Accuracy: {accuracy}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 102,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "12/12 [==============================] - 1s 37ms/step - loss: 0.4631 - accuracy: 0.8952\n",
            "Loss: 0.46305710077285767, Accuracy: 0.8951841592788696\n"
          ]
        }
      ],
      "source": [
        "# ƒê√°nh gi√° m√¥ h√¨nh tr√™n t·∫≠p ki·ªÉm tra\n",
        "loss, accuracy = model.evaluate(X_val, y_val)\n",
        "print(f\"Loss: {loss}, Accuracy: {accuracy}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "08crtvU9HWvQ"
      },
      "outputs": [],
      "source": [
        "# # Bi·ªÉu di·ªÖn m·∫´u tin t·ª©c b·∫±ng PhoBERT v√† l·∫•y ra vector embedding\n",
        "# phobert_inputs = tokenizer(data, return_tensors=\"tf\", padding=True, truncation=True, max_length=250, is_split_into_words=False)\n",
        "# phobert_outputs = phobert_model(phobert_inputs)\n",
        "# phobert_embeddings = phobert_outputs.last_hidden_state"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IrAhL4wGNPNb"
      },
      "outputs": [],
      "source": [
        "# # X√¢y d·ª±ng m√¥ h√¨nh\n",
        "# model = Sequential()\n",
        "# # tinh ch·ªânh l·∫°i tham s·ªë cho ph√π h·ª£p\n",
        "# model.add(Bidirectional(LSTM(512, return_sequences=True), input_shape=(128, 768))) #tunh chinh lai inputshape\n",
        "# model.add(Bidirectional(LSTM(256)))\n",
        "# model.add(Dense(128, activation='relu'))\n",
        "# model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "# # Bi√™n d·ªãch m√¥ h√¨nh\n",
        "# model.compile(loss='binary_crossentropy', optimizer=Adam(learning_rate=0.001), metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# from tensorflow.keras.models import Sequential\n",
        "# from tensorflow.keras.layers import Bidirectional, LSTM, Dense, Dropout\n",
        "# from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "# # X√¢y d·ª±ng m√¥ h√¨nh\n",
        "# model = Sequential()\n",
        "# # Thay ƒë·ªïi s·ªë ƒë∆°n v·ªã v√† th√™m Dropout\n",
        "# model.add(Bidirectional(LSTM(256, return_sequences=True), input_shape=(128, 768)))  # Thay ƒë·ªïi s·ªë ƒë∆°n v·ªã\n",
        "# model.add(Dropout(0.2))  # Th√™m l·ªõp Dropout ƒë·ªÉ ngƒÉn overfitting\n",
        "# model.add(Bidirectional(LSTM(128)))  # Thay ƒë·ªïi s·ªë ƒë∆°n v·ªã\n",
        "# model.add(Dropout(0.2))  # Th√™m l·ªõp Dropout\n",
        "# model.add(Dense(128, activation='relu'))\n",
        "# model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "# # Bi√™n d·ªãch m√¥ h√¨nh v·ªõi learning rate th·∫•p h∆°n v√† optimizer RMSprop\n",
        "# model.compile(loss='binary_crossentropy', optimizer=Adam(learning_rate=0.0001), metrics=['accuracy'])\n",
        "\n",
        "# # Ki·ªÉm tra c·∫•u tr√∫c m√¥ h√¨nh\n",
        "# model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R0yJZcaJNgm-",
        "outputId": "bea3ae2d-c0f7-456a-808a-b189eb1beca3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "20/20 [==============================] - 61s 2s/step - loss: 0.4381 - accuracy: 0.8119 - val_loss: 0.4191 - val_accuracy: 0.8250\n",
            "Epoch 2/10\n",
            "20/20 [==============================] - 26s 1s/step - loss: 0.2443 - accuracy: 0.9028 - val_loss: 0.3787 - val_accuracy: 0.8562\n",
            "Epoch 3/10\n",
            "20/20 [==============================] - 23s 1s/step - loss: 0.1547 - accuracy: 0.9389 - val_loss: 0.4328 - val_accuracy: 0.8125\n",
            "Epoch 4/10\n",
            "20/20 [==============================] - 26s 1s/step - loss: 0.0637 - accuracy: 0.9812 - val_loss: 0.4558 - val_accuracy: 0.8750\n",
            "Epoch 5/10\n",
            "20/20 [==============================] - 23s 1s/step - loss: 0.0259 - accuracy: 0.9922 - val_loss: 0.6098 - val_accuracy: 0.8750\n",
            "Epoch 6/10\n",
            "20/20 [==============================] - 27s 1s/step - loss: 0.0468 - accuracy: 0.9859 - val_loss: 0.5386 - val_accuracy: 0.8250\n",
            "Epoch 7/10\n",
            "20/20 [==============================] - 23s 1s/step - loss: 0.0369 - accuracy: 0.9843 - val_loss: 0.5375 - val_accuracy: 0.8500\n",
            "Epoch 8/10\n",
            "20/20 [==============================] - 27s 1s/step - loss: 0.0128 - accuracy: 0.9953 - val_loss: 0.9229 - val_accuracy: 0.8250\n",
            "Epoch 9/10\n",
            "20/20 [==============================] - 23s 1s/step - loss: 0.0884 - accuracy: 0.9702 - val_loss: 0.5551 - val_accuracy: 0.8125\n",
            "Epoch 10/10\n",
            "20/20 [==============================] - 27s 1s/step - loss: 0.0182 - accuracy: 0.9953 - val_loss: 0.7059 - val_accuracy: 0.8375\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7a12d8935210>"
            ]
          },
          "execution_count": 49,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# # Chia d·ªØ li·ªáu th√†nh t·∫≠p hu·∫•n luy·ªán v√† t·∫≠p ki·ªÉm tra\n",
        "# split_ratio = 0.8\n",
        "# split_index = int(len(texts) * split_ratio)\n",
        "\n",
        "# X_train = np.array(phobert_embeddings[:split_index])\n",
        "# X_test = np.array(phobert_embeddings[split_index:])\n",
        "# y_train = np.array(labels[:split_index])\n",
        "# y_test = np.array(labels[split_index:])\n",
        "\n",
        "# # Hu·∫•n luy·ªán m√¥ h√¨nh\n",
        "# model.fit(X_train, y_train, epochs=10, batch_size=32, validation_split=0.2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "455opDoUNkLb",
        "outputId": "84eba698-cb5d-43da-8130-5df80063e774"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "4/4 [==============================] - 0s 49ms/step - loss: 0.0616 - accuracy: 0.9840\n",
            "Loss: 0.06160259246826172, Accuracy: 0.984000027179718\n"
          ]
        }
      ],
      "source": [
        "# # ƒê√°nh gi√° m√¥ h√¨nh tr√™n t·∫≠p ki·ªÉm tra\n",
        "# loss, accuracy = model.evaluate(X_test, y_test)\n",
        "# print(f\"Loss: {loss}, Accuracy: {accuracy}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {},
      "outputs": [],
      "source": [
        "from transformers import T5ForConditionalGeneration, T5Tokenizer, AutoModel, AutoTokenizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "You are using the default legacy behaviour of the <class 'transformers.models.t5.tokenization_t5.T5Tokenizer'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thouroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565\n"
          ]
        }
      ],
      "source": [
        "def load_T5():\n",
        "    t5_model = T5ForConditionalGeneration.from_pretrained(\"NlpHUST/t5-small-vi-summarization\")\n",
        "    t5_tokenizer = T5Tokenizer.from_pretrained(\"NlpHUST/t5-small-vi-summarization\")\n",
        "    return t5_model, t5_tokenizer\n",
        "t5_model, t5_tokenizer = load_T5()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {},
      "outputs": [],
      "source": [
        "def summarize(sentence):\n",
        "    with torch.no_grad():\n",
        "        tokenized_text = t5_tokenizer.encode(sentence, return_tensors=\"pt\")\n",
        "        summary_ids = t5_model.generate(tokenized_text, max_length=256, num_beams=5,\n",
        "                                     repetition_penalty=2.5, length_penalty=1.0, early_stopping=True)\n",
        "    return t5_tokenizer.decode(summary_ids[0], skip_special_tokens=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 106,
      "metadata": {},
      "outputs": [],
      "source": [
        "def preprocess(text):\n",
        "    \n",
        "    text = re.sub(r'http\\S+', '', text)\n",
        "\n",
        "    text = re.sub(r'[^\\w\\s\\d+]', '', text)\n",
        "\n",
        "    text = text.lower()\n",
        "\n",
        "    tokens = ViTokenizer.tokenize(text).split()\n",
        "\n",
        "    stopwords_file = '/Users/quocminh/Desktop/ƒêoÃÇÃÄ AÃÅn/chinh thuc/final/stop_word.txt'\n",
        "    with open(stopwords_file, 'r', encoding='utf-8') as f:\n",
        "        stop_words = set([line.strip() for line in f])\n",
        "\n",
        "    tokens = [token for token in tokens if token not in stop_words]\n",
        "\n",
        "    tokens = [token.replace('\\n', ' ') for token in tokens]\n",
        "\n",
        "    text = ' '.join(tokens)\n",
        "\n",
        "    return text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 108,
      "metadata": {},
      "outputs": [],
      "source": [
        "import torch\n",
        "import re\n",
        "from pyvi import ViTokenizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 115,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some layers from the model checkpoint at vinai/phobert-base were not used when initializing TFRobertaModel: ['lm_head']\n",
            "- This IS expected if you are initializing TFRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing TFRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "All the layers of TFRobertaModel were initialized from the model checkpoint at vinai/phobert-base.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFRobertaModel for predictions without further training.\n"
          ]
        }
      ],
      "source": [
        "def load_bert():\n",
        "    tokenizer = PhobertTokenizer.from_pretrained(\"vinai/phobert-base\")\n",
        "    phobert_model = TFRobertaModel.from_pretrained(\"vinai/phobert-base\")\n",
        "    return tokenizer, phobert_model\n",
        "tokenizer, phobert_model = load_bert()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 103,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Tokenize d·ªØ li·ªáu v√† l·∫•y vector embedding\n",
        "def phobert_process(data):\n",
        "    phobert_inputs = tokenizer(data, return_tensors=\"tf\", padding=True, truncation=True, max_length=106, is_split_into_words=False)\n",
        "    phobert_outputs = phobert_model(phobert_inputs)\n",
        "    phobert_embeddings = phobert_outputs.last_hidden_state\n",
        "    return phobert_embeddings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 169,
      "metadata": {},
      "outputs": [],
      "source": [
        "sentence = '''\n",
        "ng∆∞·ªùi trong h√¨nh t·ª± thi√™u do b·ª©c x√∫c c√°ch ch·ªëng d·ªãch COVID-19\n",
        "'''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 170,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1/1 [==============================] - 0s 47ms/step\n",
            "Predicted Label: 0\n",
            "0.0002354773\n",
            "This is a real news.\n"
          ]
        }
      ],
      "source": [
        "\n",
        "result = phobert_process(preprocess((sentence)))\n",
        "prediction = model.predict(result)\n",
        "print(f\"Predicted Label: {int(round(prediction[0][0]))}\")\n",
        "print(prediction[0][0])\n",
        "\n",
        "if (round(prediction[0][0])) == 0:\n",
        "    print('This is a real news.')\n",
        "else:\n",
        "    print('This is a fake news.')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 131,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "11/11 [==============================] - 0s 28ms/step\n",
            "F1-score: 0.6994535519125683\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import f1_score\n",
        "\n",
        "# T√≠nh to√°n F1-score\n",
        "test_predictions = model.predict(X_test)\n",
        "# Chuy·ªÉn ƒë·ªïi d·ª± ƒëo√°n th√†nh nh√£n (v√≠ d·ª•: v·ªõi m√¥ h√¨nh binary classification)\n",
        "predicted_labels = (test_predictions > 0.5).astype(int)\n",
        "f1 = f1_score(y_test, predicted_labels)\n",
        "print(\"F1-score:\", f1)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 132,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "AUC: 0.8912089088767534\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import roc_auc_score\n",
        "\n",
        "# T√≠nh to√°n AUC\n",
        "auc = roc_auc_score(y_test, predicted_labels)\n",
        "print(\"AUC:\", auc)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'Nh·ªØng ng∆∞·ªùi ƒë√†n b√† ho√° ƒë√° sau m·ªôt ƒë√™m ƒëi v≈© tr∆∞·ªùng bay nh·∫£y c√πng c√°c d√¢n ch∆°i trong x√≥m tr·ªç. Nhi·ªÅu ng∆∞·ªùi ƒë√†n b√† ho√° ƒë√° sau m·ªôt ƒë√™m ƒëi v≈© tr∆∞·ªùng bay nh·∫£y c√πng c√°c d√¢n ch∆°i trong x√≥m tr·ªç. M·∫•y ng√†y qua, tin n√≥ng b√†n ho√†ng d∆∞ lu·∫≠n m·∫•y ng√†y qua.'"
            ]
          },
          "execution_count": 42,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "summarize(sentence)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[0.00694228]]\n"
          ]
        }
      ],
      "source": [
        "print(prediction)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 110,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k5cbP0xHSpJU",
        "outputId": "528b8520-0bc7-4881-bd46-b2e1ab42a080"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "python(9930) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: joblib in /Users/quocminh/miniconda3/lib/python3.11/site-packages (1.3.2)\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "source": [
        "pip install joblib"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 111,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EexRytUxSwBv",
        "outputId": "1b813514-567a-4c8d-8083-56e1e9732d6f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['/Users/quocminh/Desktop/ƒêoÃÇÃÄ AÃÅn/chinh thuc/save model/vlsp_3_2_2024.pkl']"
            ]
          },
          "execution_count": 111,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import joblib\n",
        "\n",
        "# ƒê∆∞·ªùng d·∫´n ƒë·ªÉ l∆∞u m√¥ h√¨nh\n",
        "model_path = \"/Users/quocminh/Desktop/ƒêoÃÇÃÄ AÃÅn/chinh thuc/save model/vlsp_3_2_2024.pkl\"\n",
        "\n",
        "# L∆∞u m√¥ h√¨nh v√†o t·ªáp tin\n",
        "joblib.dump(model, model_path)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 112,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /Users/quocminh/Desktop/ƒêoÃÇÃÄ AÃÅn/chinh thuc/save model/vlsp_3_2_2024/assets\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /Users/quocminh/Desktop/ƒêoÃÇÃÄ AÃÅn/chinh thuc/save model/vlsp_3_2_2024/assets\n"
          ]
        }
      ],
      "source": [
        "model.save('/Users/quocminh/Desktop/ƒêoÃÇÃÄ AÃÅn/chinh thuc/save model/vlsp_3_2_2024')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 113,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /Users/quocminh/Desktop/ƒêoÃÇÃÄ AÃÅn/chinh thuc/save model/vlsp_3_2_2024/assets\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /Users/quocminh/Desktop/ƒêoÃÇÃÄ AÃÅn/chinh thuc/save model/vlsp_3_2_2024/assets\n"
          ]
        }
      ],
      "source": [
        "model.save(\"/Users/quocminh/Desktop/ƒêoÃÇÃÄ AÃÅn/chinh thuc/save model/vlsp_3_2_2024\", save_format='tf')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 114,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/quocminh/miniconda3/lib/python3.11/site-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        }
      ],
      "source": [
        "# L∆∞u to√†n b·ªô m√¥ h√¨nh, bao g·ªìm ki·∫øn tr√∫c, tr√¨nh t·ªëi ∆∞u v√† tr·ªçng s·ªë ƒë√£ h·ªçc\n",
        "model.save(\"/Users/quocminh/Desktop/ƒêoÃÇÃÄ AÃÅn/chinh thuc/save model/vlsp_3_2_2024.h5\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
